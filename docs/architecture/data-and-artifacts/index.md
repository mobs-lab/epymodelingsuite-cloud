# Data and Artifacts

The pipeline works with two categories of data: **experiment data** (input configurations that define what to simulate) and **artifacts** (intermediate and final files produced by each stage).

- **[Experiment Data](experiment-data.md)**: Repository structure, configuration files, and how data is sourced in cloud vs local mode
- **[Pipeline Artifacts](pipeline-artifacts.md)**: Builder, runner, and output artifacts with schema details

## Next Steps

- **[Pipeline Stages](../pipeline-stages.md)**: How each stage processes data
- **[Execution Modes](../execution-modes.md)**: Cloud vs local data sourcing
- **[Storage Abstraction](../storage-abstraction.md)**: Storage API details
