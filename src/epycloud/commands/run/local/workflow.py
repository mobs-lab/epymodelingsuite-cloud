"""Local workflow execution for run command."""

from pathlib import Path
from typing import Any

from epycloud.lib.command_helpers import generate_run_id, get_docker_config
from epycloud.lib.output import error, info, success

from ..validation import build_base_confirmation_info, prompt_user_confirmation
from .docker_compose import run_docker_compose_stage


def run_workflow_local(
    ctx: dict[str, Any],
    config: dict[str, Any],
    exp_id: str,
    run_id: str | None,
    skip_output: bool,
    output_config: str | None,
    auto_confirm: bool,
    verbose: bool,
    dry_run: bool,
    project_directory: Path,
) -> int:
    """Run complete workflow locally with docker compose.

    Parameters
    ----------
    ctx : dict[str, Any]
        Command context
    config : dict[str, Any]
        Configuration dict
    exp_id : str
        Experiment ID
    run_id : str | None
        Optional run ID
    skip_output : bool
        Skip stage C
    output_config : str | None
        Output config filename for Stage C (e.g., "output_projection.yaml")
    auto_confirm : bool
        Auto-confirm without prompting
    verbose : bool
        Verbose output
    dry_run : bool
        Dry run mode
    project_directory : Path
        Absolute path to Docker Compose project directory

    Returns
    -------
    int
        Exit code
    """
    # Get config values
    docker = get_docker_config(config)
    image_name = docker["image_name"]
    image_tag = docker["image_tag"]
    pipeline = config.get("pipeline", {})
    dir_prefix = pipeline.get("dir_prefix", "pipeline/flu/")

    # Generate run ID if not provided
    if not run_id:
        run_id = generate_run_id()

    # Build storage path
    storage_path = f"./local/bucket/{dir_prefix}{exp_id}/{run_id}/"

    # Build confirmation info
    confirmation_info = build_base_confirmation_info(ctx, "workflow", exp_id, run_id)
    confirmation_info.update(
        {
            "storage_path": storage_path,
            "skip_output": skip_output,
            "output_config": output_config,
            "image_name": image_name,
            "image_tag": image_tag,
        }
    )

    # Show confirmation and prompt
    if not prompt_user_confirmation(auto_confirm, confirmation_info, mode="local"):
        return 0

    info("Running workflow locally with Docker Compose...")
    info(f"Experiment ID: {exp_id}")
    info(f"Run ID: {run_id}")
    info(f"Project directory: {project_directory}")

    # Stage A: Builder
    info("")
    info("=" * 60)
    info("Stage A: Builder (generating input files)")
    info("=" * 60)

    result = run_docker_compose_stage(
        project_directory=project_directory,
        service="builder",
        env_vars={"EXP_ID": exp_id, "RUN_ID": run_id},
        dry_run=dry_run,
    )

    if result != 0:
        error("Stage A failed")
        return result

    success("Stage A completed successfully")

    # Detect number of tasks from builder artifacts
    bucket_path = (
        project_directory
        / "local"
        / "bucket"
        / dir_prefix.rstrip("/")
        / exp_id
        / run_id
        / "builder-artifacts"
    )

    if not dry_run:
        if not bucket_path.exists():
            error(f"Builder artifacts not found: {bucket_path}")
            return 1

        input_files = list(bucket_path.glob("input_*.pkl*"))
        num_tasks = len(input_files)

        if num_tasks == 0:
            error("No input files generated by builder")
            return 1

        info(f"Found {num_tasks} tasks to run")
    else:
        num_tasks = 10  # Dummy value for dry run

    # Stage B: Runner (all tasks)
    info("")
    info("=" * 60)
    info(f"Stage B: Runner (processing {num_tasks} tasks)")
    info("=" * 60)

    for task_idx in range(num_tasks):
        info(f"Running task {task_idx + 1}/{num_tasks}...")

        result = run_docker_compose_stage(
            project_directory=project_directory,
            service="runner",
            env_vars={
                "EXP_ID": exp_id,
                "RUN_ID": run_id,
                "TASK_INDEX": str(task_idx),
            },
            dry_run=dry_run,
        )

        if result != 0:
            error(f"Task {task_idx} failed")
            return result

    success("Stage B completed successfully")

    # Stage C: Output (unless skipped)
    if not skip_output:
        info("")
        info("=" * 60)
        info("Stage C: Output (generating results)")
        info("=" * 60)

        result = run_docker_compose_stage(
            project_directory=project_directory,
            service="output",
            env_vars={
                "EXP_ID": exp_id,
                "RUN_ID": run_id,
                "NUM_TASKS": str(num_tasks),
                "OUTPUT_CONFIG_FILE": output_config or "",
            },
            dry_run=dry_run,
        )

        if result != 0:
            error("Stage C failed")
            return result

        success("Stage C completed successfully")
    else:
        info("")
        info("Stage C skipped (--skip-output)")

    # Summary
    info("")
    info("=" * 60)
    success("Workflow completed successfully!")
    info("=" * 60)
    info(f"Results in: ./local/bucket/{dir_prefix}{exp_id}/{run_id}/")

    return 0
